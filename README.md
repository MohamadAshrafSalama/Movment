# Professional Human Pose Detection with TensorFlow MoveNet

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow 2.19+](https://img.shields.io/badge/TensorFlow-2.19+-orange.svg)](https://tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A professional-grade human pose detection pipeline using TensorFlow's MoveNet model. This project provides comprehensive video analysis with automatic model management, multiple output formats, and system timestamp integration.

## ğŸŒŸ Features

- **ğŸ¤– Advanced Pose Detection**: Uses TensorFlow MoveNet Lightning for fast and accurate pose detection
- **ğŸ“¦ Automatic Model Management**: Downloads and caches models locally for faster subsequent runs
- **ğŸ¯ Multiple Output Formats**: Generates CSV data and two annotation video formats
- **â° Dual Timestamp System**: Records both video timestamps and real-time system timestamps
- **ğŸ—ï¸ Professional Architecture**: Clean, modular code with proper error handling and logging
- **ğŸ Environment Management**: Supports both conda and pip virtual environments
- **ğŸ“Š Progress Tracking**: Real-time progress bars and performance metrics
- **ğŸ”§ Command-Line Interface**: Easy-to-use CLI with multiple options

## ğŸ“ Project Structure

```
pose-detection/
â”œâ”€â”€ pose_detection_professional.py  # Main application
â”œâ”€â”€ environment.yml                 # Conda environment file
â”œâ”€â”€ requirements.txt                # Pip requirements
â”œâ”€â”€ setup.py                       # Package setup
â”œâ”€â”€ setup_environment.sh           # Automated setup script
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ models/                        # Auto-created model cache
â””â”€â”€ output/                        # Generated outputs
    â”œâ”€â”€ {video_name}_keypoints.csv
    â”œâ”€â”€ {video_name}_annotations_black.mp4
    â””â”€â”€ {video_name}_annotations_white.mp4
```

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

```bash
# Clone or download the project
# Navigate to project directory
cd pose-detection

# Run automated setup
./setup_environment.sh

# Activate environment (conda)
conda activate pose-detection

# OR activate environment (pip)
source pose_detection_env/bin/activate

# Run pose detection
python pose_detection_professional.py --input "your_video.mp4"
```

### Option 2: Manual Setup

#### Using Conda (Recommended)

```bash
# Create environment
conda env create -f environment.yml

# Activate environment
conda activate pose-detection

# Run application
python pose_detection_professional.py --input "your_video.mp4"
```

#### Using Pip

```bash
# Create virtual environment
python3 -m venv pose_detection_env

# Activate environment
source pose_detection_env/bin/activate  # Linux/Mac
# OR
pose_detection_env\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt

# Run application
python pose_detection_professional.py --input "your_video.mp4"
```

## ğŸ“Š Outputs

### 1. CSV File (`{video_name}_keypoints.csv`)
Comprehensive data file containing:
- **video_timestamp**: Time in video (seconds from start)
- **system_timestamp**: Real-time system timestamp (ISO format)
- **frame_number**: Sequential frame number
- **17 Keypoints**: Each with y, x coordinates and confidence scores

**Example data structure:**
```csv
video_timestamp,system_timestamp,frame_number,nose_y,nose_x,nose_confidence,...
0.0,2025-06-29T14:04:11.838314,0,144.76,167.05,0.579,...
0.033,2025-06-29T14:04:12.083812,1,141.52,166.68,0.477,...
```

### 2. Black Background Video (`{video_name}_annotations_black.mp4`)
- Pure annotation video with black background
- Cyan keypoints (â—‹) and yellow connections (â”€)
- White text overlays showing timestamps and frame numbers
- Perfect for analysis and presentations

### 3. White Background Video (`{video_name}_annotations_white.mp4`)
- Pure annotation video with white background
- Blue keypoints (â—‹) and red connections (â”€)
- Black text overlays showing timestamps and frame numbers
- Ideal for printing and documentation

## ğŸ¯ Detected Keypoints (17 total)

| Category | Keypoints |
|----------|-----------|
| **Face** | nose, left_eye, right_eye, left_ear, right_ear |
| **Arms** | left_shoulder, right_shoulder, left_elbow, right_elbow, left_wrist, right_wrist |
| **Torso** | left_hip, right_hip |
| **Legs** | left_knee, right_knee, left_ankle, right_ankle |

## ğŸ”§ Command Line Usage

```bash
# Basic usage
python pose_detection_professional.py --input video.mp4

# Specify output directory
python pose_detection_professional.py --input video.mp4 --output results/

# Enable verbose logging
python pose_detection_professional.py --input video.mp4 --verbose

# Show help
python pose_detection_professional.py --help
```

### Command Line Arguments

| Argument | Short | Description | Default |
|----------|-------|-------------|---------|
| `--input` | `-i` | Input video file path (required) | - |
| `--output` | `-o` | Output directory | `output` |
| `--verbose` | `-v` | Enable verbose logging | `False` |

## ğŸš€ Performance

- **Processing Speed**: ~65 fps on modern hardware
- **Model**: MoveNet Lightning (192x192 input)
- **Confidence Threshold**: 0.3 for visualization
- **Memory Usage**: ~2GB RAM for typical videos
- **Model Size**: ~7MB cached locally

### Typical Processing Times
| Video Length | Processing Time | Output Size |
|--------------|----------------|-------------|
| 30 seconds | ~15 seconds | ~12MB videos, ~0.6MB CSV |
| 2 minutes | ~60 seconds | ~50MB videos, ~2.4MB CSV |
| 5 minutes | ~150 seconds | ~125MB videos, ~6MB CSV |

## ğŸ”§ Model Management

The application automatically handles model downloading and caching:

1. **First Run**: Downloads MoveNet model from TensorFlow Hub (~50MB)
2. **Subsequent Runs**: Loads model from local cache (`models/` directory)
3. **Cache Validation**: Automatically re-downloads if cache is corrupted
4. **Offline Support**: Works offline after initial model download

## ğŸ“‹ Requirements

- **Python**: 3.8 or higher
- **Operating System**: macOS, Linux, Windows
- **Memory**: 4GB RAM minimum, 8GB recommended
- **Storage**: 1GB free space for model cache and outputs
- **Network**: Internet connection for initial model download

## ğŸ› ï¸ Development

### Project Architecture

```python
# Main components
Config()           # Configuration management
ModelManager()     # TensorFlow model handling
PoseDetector()     # Core pose detection logic
VideoProcessor()   # Video processing pipeline
```

### Code Quality Features

- **Type Hints**: Full type annotation for better IDE support
- **Logging**: Comprehensive logging with configurable levels
- **Error Handling**: Robust error handling with informative messages
- **Documentation**: Detailed docstrings and comments
- **Modular Design**: Clean separation of concerns

## ğŸ› Troubleshooting

### Common Issues

1. **Model Download Fails**
   ```bash
   # Clear cache and retry
   rm -rf models/
   python pose_detection_professional.py --input video.mp4
   ```

2. **Out of Memory Error**
   ```bash
   # Process shorter video segments or reduce video resolution
   ```

3. **Video Not Found**
   ```bash
   # Check file path and ensure video file exists
   ls -la your_video.mp4
   ```

4. **OpenCV Issues**
   ```bash
   # Reinstall opencv-python
   pip uninstall opencv-python
   pip install opencv-python
   ```

## ğŸ“ˆ Customization

### Modify Confidence Threshold
```python
# In pose_detection_professional.py
class Config:
    CONFIDENCE_THRESHOLD = 0.5  # Change from 0.3 to 0.5
```

### Change Model
```python
# Switch to Thunder model for higher accuracy
class Config:
    MODEL_URL = "https://tfhub.dev/google/movenet/singlepose/thunder/4"
    INPUT_SIZE = 256
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ Support

For issues and questions:
1. Check the troubleshooting section above
2. Search existing issues in the repository
3. Create a new issue with detailed information

---

**Built with â¤ï¸ using TensorFlow and OpenCV** 